{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profile_url(text: str) -> str:\n",
    "    \"Searches for LinkedIn profile Pages\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.agents import Tool, create_react_agent, AgentExecutor\n",
    "\n",
    "\n",
    "\n",
    "def lookup(name: str) -> str:\n",
    "\n",
    "    template = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "    {tools}\n",
    "\n",
    "    Use the following format:\n",
    "\n",
    "    Question: the input question you must answer\n",
    "    Thought: you should always think about what to do\n",
    "    Action: the action to take, should be one of [{tool_names}]\n",
    "    Action Input: the input to the action\n",
    "    Observation: the result of the action\n",
    "    ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "    Thought: I now know the final answer\n",
    "    Final Answer: the final answer to the original input question\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    Question:given the full name {input} I want you to get it me a link to their LinkedIn profile page.\n",
    "    your answer should contain only a URL\n",
    "    Thought:{agent_scratchpad}\n",
    "    \"\"\"\n",
    "\n",
    "    tools_for_agent = []\n",
    "\n",
    "    llm = ''\n",
    "\n",
    "    prompt_template = PromptTemplate(template=template, input_variables=[\"input\"])\n",
    "\n",
    "    agent = create_react_agent(llm=llm, tools=tools_for_agent, prompt=prompt_template)\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=agent,\n",
    "        tools=tools_for_agent,\n",
    "        return_intermediate_steps=True,\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True,\n",
    "    )\n",
    "    linkedin_profile_url = agent_executor.invoke({\"input\": name})\n",
    "\n",
    "    for k, v in linkedin_profile_url.items():\n",
    "        if k == \"output\":\n",
    "            return v\n",
    "\n",
    "    # return 'https://www.linkedin.com/in/satyanadella'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/react\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': 'ServiceDesk'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "template = \"\"\"You are an AI assistant designed to classify user queries. Your task is to determine whether a given query is a normal conversation or a ServiceDesk conversation. \n",
    "    A normal conversation includes everyday, casual, or non-service-related topics. Examples include discussing hobbies, plans, general inquiries, and personal matters.\n",
    "    A ServiceDesk conversation involves requests for assistance, support issues, troubleshooting, or inquiries related to IT services, technical support, or customer service.\n",
    "    For each query, respond with either \"Conversation\" if it is a normal conversation or \"ServiceDesk\" if it is a ServiceDesk conversation.\n",
    "    \n",
    "    Return the classfication a JSON with a single key 'result' and no premable or explaination.\n",
    "\n",
    "    Query: {query}\n",
    "    Classification: \n",
    "    \"\"\"\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    ")\n",
    "\n",
    "name = \"what is mac new version?\"\n",
    "\n",
    "prompt_template = PromptTemplate(template=template, input_variables=[\"query\"])\n",
    "chain = prompt_template | model | JsonOutputParser()\n",
    "response = chain.invoke({\"query\": name})\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
